{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNXaYleq_vaq"
      },
      "source": [
        "<center>\n",
        "    <h1> Natural Language Processing and Large Language Models for Research Data Exploration and Analysis\n",
        " </h1> </center>\n",
        "\n",
        "<center> <h1> Day-1: Basic Text Processing  </h1> </center>\n",
        "\n",
        "<center> <h2> Sample code </h2> </center>\n",
        "\n",
        "<center> <h4> Raghava Mukkamala (rrm.digi@cbs.dk)  </h4> </center>\n",
        "\n",
        "\n",
        "### Instructions\n",
        "\n",
        "#### If you are working on a Jupyter Notebook, you will most likely need to install libraries using e.g. !pip install. On Google Colab most libraries should come preinstalled. Remember to import the in any case libraries!\n",
        "\n",
        "#### Here we show some of the different text processing steps using the libraries TextBlob and nltk. Note that for most NLP tasks, there are many alternatives regarding libraries to use.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "V7OCqN7c_vas"
      },
      "outputs": [],
      "source": [
        "# !pip install --upgrade numpy\n",
        "# !pip install prettytable\n",
        "# !pip install spacy\n",
        "# !pip install nltk\n",
        "# !pip install textblob\n",
        "\n",
        "import nltk\n",
        "from textblob import TextBlob\n",
        "from prettytable import PrettyTable"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading required resources\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('maxent_ne_chunker_tab')\n",
        "nltk.download('words')\n",
        "nltk.download('brown')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMkUArQuSAKG",
        "outputId": "ab8a3b3c-ad4e-4837-9b26-601f0d89cc5c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker_tab is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rz1LvlCz_vau"
      },
      "source": [
        "## Tokenization: splitting text into words\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using only TextBlob\n",
        "\n",
        "text = (\"Natural language processing (NLP) is a field \" +\n",
        "       \"of computer science, artificial intelligence \" +\n",
        "       \"and computational linguistics concerned with \" +\n",
        "       \"the interactions between computers and human \" +\n",
        "       \"(natural) languages, and, in particular, \" +\n",
        "       \"concerned with programming computers to \" +\n",
        "       \"fruitfully process large natural language \" +\n",
        "       \"corpora. Challenges in natural language \" +\n",
        "       \"processing frequently involve natural \" +\n",
        "       \"language understanding, natural language\" +\n",
        "       \"generation frequently from formal, machine\" +\n",
        "       \"-readable logical forms), connecting language \" +\n",
        "       \"and machine perception, managing human-\" +\n",
        "       \"computer dialog systems, or some combination \" +\n",
        "       \"thereof.\")\n",
        "\n",
        "# If you want to use a shorter text, comment out the one above and use the one below instead.\n",
        "\n",
        "#text = \"Apple is looking at buying U.K. startup for $1 billion\"\n",
        "\n",
        "# create a TextBlob object\n",
        "tb = TextBlob(text)\n",
        "\n",
        "# tokenize the text into words.\n",
        "print(\"Words :\\n\", tb.words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHN_Z15UJoh3",
        "outputId": "392eba60-d9c2-489a-9a2b-234fc23df883"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words :\n",
            " ['Natural', 'language', 'processing', 'NLP', 'is', 'a', 'field', 'of', 'computer', 'science', 'artificial', 'intelligence', 'and', 'computational', 'linguistics', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', 'natural', 'languages', 'and', 'in', 'particular', 'concerned', 'with', 'programming', 'computers', 'to', 'fruitfully', 'process', 'large', 'natural', 'language', 'corpora', 'Challenges', 'in', 'natural', 'language', 'processing', 'frequently', 'involve', 'natural', 'language', 'understanding', 'natural', 'languagegeneration', 'frequently', 'from', 'formal', 'machine-readable', 'logical', 'forms', 'connecting', 'language', 'and', 'machine', 'perception', 'managing', 'human-computer', 'dialog', 'systems', 'or', 'some', 'combination', 'thereof']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InTJwltY_vav",
        "outputId": "3bd9b06d-5929-4e95-a40e-e87e9d09739f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw Document:  Natural language processing (NLP) is a field of computer science, artificial intelligence and computational linguistics concerned with the interactions between computers and human (natural) languages, and, in particular, concerned with programming computers to fruitfully process large natural language corpora. Challenges in natural language processing frequently involve natural language understanding, natural languagegeneration frequently from formal, machine-readable logical forms), connecting language and machine perception, managing human-computer dialog systems, or some combination thereof. \n",
            "\n",
            "+-------+--------------------+\n",
            "| index |        word        |\n",
            "+-------+--------------------+\n",
            "|   0   |      Natural       |\n",
            "|   1   |      language      |\n",
            "|   2   |     processing     |\n",
            "|   3   |        NLP         |\n",
            "|   4   |         is         |\n",
            "|   5   |         a          |\n",
            "|   6   |       field        |\n",
            "|   7   |         of         |\n",
            "|   8   |      computer      |\n",
            "|   9   |      science       |\n",
            "|   10  |     artificial     |\n",
            "|   11  |    intelligence    |\n",
            "|   12  |        and         |\n",
            "|   13  |   computational    |\n",
            "|   14  |    linguistics     |\n",
            "|   15  |     concerned      |\n",
            "|   16  |        with        |\n",
            "|   17  |        the         |\n",
            "|   18  |    interactions    |\n",
            "|   19  |      between       |\n",
            "|   20  |     computers      |\n",
            "|   21  |        and         |\n",
            "|   22  |       human        |\n",
            "|   23  |      natural       |\n",
            "|   24  |     languages      |\n",
            "|   25  |        and         |\n",
            "|   26  |         in         |\n",
            "|   27  |     particular     |\n",
            "|   28  |     concerned      |\n",
            "|   29  |        with        |\n",
            "|   30  |    programming     |\n",
            "|   31  |     computers      |\n",
            "|   32  |         to         |\n",
            "|   33  |     fruitfully     |\n",
            "|   34  |      process       |\n",
            "|   35  |       large        |\n",
            "|   36  |      natural       |\n",
            "|   37  |      language      |\n",
            "|   38  |      corpora       |\n",
            "|   39  |     Challenges     |\n",
            "|   40  |         in         |\n",
            "|   41  |      natural       |\n",
            "|   42  |      language      |\n",
            "|   43  |     processing     |\n",
            "|   44  |     frequently     |\n",
            "|   45  |      involve       |\n",
            "|   46  |      natural       |\n",
            "|   47  |      language      |\n",
            "|   48  |   understanding    |\n",
            "|   49  |      natural       |\n",
            "|   50  | languagegeneration |\n",
            "|   51  |     frequently     |\n",
            "|   52  |        from        |\n",
            "|   53  |       formal       |\n",
            "|   54  |  machine-readable  |\n",
            "|   55  |      logical       |\n",
            "|   56  |       forms        |\n",
            "|   57  |     connecting     |\n",
            "|   58  |      language      |\n",
            "|   59  |        and         |\n",
            "|   60  |      machine       |\n",
            "|   61  |     perception     |\n",
            "|   62  |      managing      |\n",
            "|   63  |   human-computer   |\n",
            "|   64  |       dialog       |\n",
            "|   65  |      systems       |\n",
            "|   66  |         or         |\n",
            "|   67  |        some        |\n",
            "|   68  |    combination     |\n",
            "|   69  |      thereof       |\n",
            "+-------+--------------------+\n"
          ]
        }
      ],
      "source": [
        "# Using TextBlob and PrettyTable\n",
        "\n",
        "tb = TextBlob(text)\n",
        "print('Raw Document: ', tb, \"\\n\")\n",
        "\n",
        "index = 0\n",
        "tab = PrettyTable(['index','word'])\n",
        "\n",
        "for word in tb.words:\n",
        "    tab.add_row([index,word])\n",
        "    index += 1\n",
        "\n",
        "print(tab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70M-fo9__vav"
      },
      "source": [
        "## Parts of Speech Tagging and Entity Recongition\n",
        "\n",
        "### POS tagging with nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bunGWX4K_vaw",
        "outputId": "87cf7d76-4a52-4cfb-c434-3f96ff880eed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  they/PRP\n",
            "  lay/VBD\n",
            "  back/RB\n",
            "  on/IN\n",
            "  the/DT\n",
            "  (ORGANIZATION San/NNP Francisco/NNP)\n",
            "  grass/NN\n",
            "  in/IN\n",
            "  (GPE U.S.A./NNP)\n",
            "  and/CC\n",
            "  looked/VBD\n",
            "  at/IN\n",
            "  the/DT\n",
            "  stars/NNS\n",
            "  and/CC\n",
            "  their/PRP$)\n"
          ]
        }
      ],
      "source": [
        "from nltk import word_tokenize, pos_tag, ne_chunk\n",
        "\n",
        "sentence = 'they lay back on the San Francisco grass in U.S.A. and looked at the stars and their'\n",
        "\n",
        "print(ne_chunk(pos_tag(word_tokenize(sentence))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d75Fi1Ke_vaw"
      },
      "source": [
        "### POS tagging and Entity extraction with TextBlob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xq5-H6La_vaw",
        "outputId": "858d6c60-6ee1-48cb-9eef-783d02d30546"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Part-of-Speech Tags:\n",
            " - Elon: NNP\n",
            " - Musk: NNP\n",
            " - the: DT\n",
            " - CEO: NNP\n",
            " - of: IN\n",
            " - Tesla: NNP\n",
            " - and: CC\n",
            " - SpaceX: NNP\n",
            " - is: VBZ\n",
            " - known: VBN\n",
            " - for: IN\n",
            " - his: PRP$\n",
            " - groundbreaking: NN\n",
            " - innovations: NNS\n",
            " - in: IN\n",
            " - technology: NN\n"
          ]
        }
      ],
      "source": [
        "def pos_tagging_with_textblob(text):\n",
        "    # Create a TextBlob object\n",
        "    blob = TextBlob(text)\n",
        "\n",
        "    # Perform POS tagging\n",
        "    pos_tags = blob.tags\n",
        "\n",
        "    return pos_tags\n",
        "\n",
        "# Example text\n",
        "text = \"\"\"\n",
        "Elon Musk, the CEO of Tesla and SpaceX, is known for his groundbreaking innovations in technology.\n",
        "\"\"\"\n",
        "\n",
        "# Get POS tags\n",
        "tags = pos_tagging_with_textblob(text)\n",
        "\n",
        "# Display POS tags\n",
        "print(\"Part-of-Speech Tags:\")\n",
        "for word, tag in tags:\n",
        "    print(f\" - {word}: {tag}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NDbMw0z_vaw",
        "outputId": "2b15ef7b-3200-49d6-d14a-68c9151e7e56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Noun Phrases:\n",
            " - elon musk\n",
            " - ceo\n",
            " - tesla\n",
            " - spacex\n",
            " - june\n",
            " - pretoria\n",
            " - africa\n",
            " - paypal\n",
            " - neuralink\n"
          ]
        }
      ],
      "source": [
        "def extract_entities_with_textblob(text):\n",
        "    # Create a TextBlob object\n",
        "    blob = TextBlob(text)\n",
        "\n",
        "    # Extract noun phrases (a simple form of entity recognition)\n",
        "    noun_phrases = blob.noun_phrases\n",
        "\n",
        "    return noun_phrases\n",
        "\n",
        "# Example text\n",
        "text = \"\"\"\n",
        "Elon Musk, the CEO of Tesla and SpaceX, was born on June 28, 1971, in Pretoria, South Africa.\n",
        "He founded companies like PayPal and Neuralink and is currently one of the richest people in the world.\n",
        "\"\"\"\n",
        "\n",
        "# Extract entities (noun phrases) from the text\n",
        "entities = extract_entities_with_textblob(text)\n",
        "\n",
        "# Display extracted noun phrases\n",
        "print(\"Extracted Noun Phrases:\")\n",
        "for entity in entities:\n",
        "    print(f\" - {entity}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8plfuh4V_vaw"
      },
      "source": [
        "## Stemming and lemmatization with nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqfAa1XhGo-0",
        "outputId": "289de1be-d314-41ba-dfea-e454fcd434a2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59hEjUIn_vaw",
        "outputId": "976b5863-2291-43c2-e140-dbd978bde202"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stemming sing: sing\n",
            "lemmatize sing: sing\n",
            "\n",
            "stemming ponies: poni\n",
            "lemmatize ponies: pony\n",
            "\n",
            "stemming example: exampl\n",
            "lemmatize example: example\n",
            "\n",
            "stemming equivalent: equival\n",
            "lemmatize equivalent: equivalent\n"
          ]
        }
      ],
      "source": [
        "# Example on stemming and lemmatization\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "\n",
        "st = PorterStemmer()\n",
        "\n",
        "# lemmatization\n",
        "wnl = nltk.WordNetLemmatizer()\n",
        "\n",
        "print('stemming sing:',st.stem(\"sing\"))\n",
        "print('lemmatize sing:',wnl.lemmatize(\"sing\"))\n",
        "print('')\n",
        "print('stemming ponies:',st.stem(\"ponies\"))\n",
        "print('lemmatize ponies:',wnl.lemmatize(\"ponies\"))\n",
        "print('')\n",
        "print('stemming example:',st.stem(\"example\"))\n",
        "print('lemmatize example:', wnl.lemmatize(\"example\"))\n",
        "print('')\n",
        "print('stemming equivalent:', st.stem(\"equivalent\"))\n",
        "print('lemmatize equivalent:',wnl.lemmatize(\"equivalent\"))\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}