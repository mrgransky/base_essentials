{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5upEJXOdRA7e"
      },
      "source": [
        "<center>\n",
        "    <h1> Natural Language Processing and Large Language Models for Research Data Exploration and Analysis\n",
        " </h1> </center>\n",
        "\n",
        "<center> <h1> Day-1: Basic Text Processing  </h1> </center>\n",
        "\n",
        "<center> <h2> Exercise & solutions</h2> </center>\n",
        "\n",
        "<center> <h4> Raghava Mukkamala (rrm.digi@cbs.dk)  </h4> </center>\n",
        "\n",
        "\n",
        "### Instructions\n",
        "\n",
        "#### The following Jupyter Notebook contains 4 questions and solutions. Q1 contain directly the solution, while Q2, Q3 and Q4 first have an empty spot for you to attempt the solution, followed by the solution in the next cell. If trying to code the solutions frmo scratch feels intimidating, go through these with the goal of understanding what each line does.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pKwdTcDsRA7i"
      },
      "outputs": [],
      "source": [
        "# you can install packages in jupyter notebook by using ! in front of pip:\n",
        "\n",
        "# !pip install nltk\n",
        "# !pip install textblob\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OjuSz4iRRA7k"
      },
      "outputs": [],
      "source": [
        "# Import the libraries\n",
        "\n",
        "import nltk\n",
        "from textblob import TextBlob\n",
        "from prettytable import PrettyTable"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading required content\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_wxh6qwR3mt",
        "outputId": "971c2214-dfa2-4c67-ef2d-19688b0a5d1e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvQj9uF_RA7k"
      },
      "source": [
        "## Q.No: 1 Tokenization using Textblob\n",
        "\n",
        "Use the textblob package to split the doc1 into\n",
        "* a) sentences and\n",
        "* b) tokens\n",
        "\n",
        "and display them in tabular format.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hs-urdysRA7l",
        "outputId": "0d2967ff-5117-493e-9b94-de8c04c85be5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw Document :   A. A. Milne: The third-rate mind is only happy when it is thinking  with the majority. The second-rate mind is only happy  when it is thinking with the minority.  The first-rate mind is only happy when it is thinking.  \n",
            "\n",
            "+-------+-------------------------------------------------------------------------------------+\n",
            "| Index |                                      Sentences                                      |\n",
            "+-------+-------------------------------------------------------------------------------------+\n",
            "|   0   |                                          A.                                         |\n",
            "|   1   | A. Milne: The third-rate mind is only happy when it is thinking  with the majority. |\n",
            "|   2   |      The second-rate mind is only happy  when it is thinking with the minority.     |\n",
            "|   3   |                The first-rate mind is only happy when it is thinking.               |\n",
            "+-------+-------------------------------------------------------------------------------------+\n",
            "+-------+-------------+\n",
            "| index |    Tokens   |\n",
            "+-------+-------------+\n",
            "|   4   |      A      |\n",
            "|   5   |      .      |\n",
            "|   6   |      A.     |\n",
            "|   7   |    Milne    |\n",
            "|   8   |      :      |\n",
            "|   9   |     The     |\n",
            "|   10  |  third-rate |\n",
            "|   11  |     mind    |\n",
            "|   12  |      is     |\n",
            "|   13  |     only    |\n",
            "|   14  |    happy    |\n",
            "|   15  |     when    |\n",
            "|   16  |      it     |\n",
            "|   17  |      is     |\n",
            "|   18  |   thinking  |\n",
            "|   19  |     with    |\n",
            "|   20  |     the     |\n",
            "|   21  |   majority  |\n",
            "|   22  |      .      |\n",
            "|   23  |     The     |\n",
            "|   24  | second-rate |\n",
            "|   25  |     mind    |\n",
            "|   26  |      is     |\n",
            "|   27  |     only    |\n",
            "|   28  |    happy    |\n",
            "|   29  |     when    |\n",
            "|   30  |      it     |\n",
            "|   31  |      is     |\n",
            "|   32  |   thinking  |\n",
            "|   33  |     with    |\n",
            "|   34  |     the     |\n",
            "|   35  |   minority  |\n",
            "|   36  |      .      |\n",
            "|   37  |     The     |\n",
            "|   38  |  first-rate |\n",
            "|   39  |     mind    |\n",
            "|   40  |      is     |\n",
            "|   41  |     only    |\n",
            "|   42  |    happy    |\n",
            "|   43  |     when    |\n",
            "|   44  |      it     |\n",
            "|   45  |      is     |\n",
            "|   46  |   thinking  |\n",
            "|   47  |      .      |\n",
            "+-------+-------------+\n"
          ]
        }
      ],
      "source": [
        "doc1 =\"\"\"\n",
        "A. A. Milne: The third-rate mind is only happy when it is thinking\n",
        "with the majority. The second-rate mind is only happy\n",
        "when it is thinking with the minority.\n",
        "The first-rate mind is only happy when it is thinking.\n",
        "\"\"\"\n",
        "\n",
        "# remove newlines\n",
        "doc1 = doc1.replace(\"\\n\", \" \")\n",
        "\n",
        "# instantiate TextBlob on doc1\n",
        "tb1 = TextBlob(doc1)\n",
        "\n",
        "# document can be printed out in a regular form using the instantiated object\n",
        "print('Raw Document : ', tb1, \"\\n\")\n",
        "\n",
        "index = 0\n",
        "\n",
        "# instantiate PrettyTable with columns Index and Sentences\n",
        "tab = PrettyTable(['Index','Sentences'])\n",
        "\n",
        "# iterate over sentences in tb1 and append them to new rows of the tab\n",
        "for sen in tb1.sentences:\n",
        "    tab.add_row([index,sen])\n",
        "    index += 1\n",
        "\n",
        "print(tab)\n",
        "\n",
        "tab = PrettyTable(['index','Tokens'])\n",
        "\n",
        "# iterate over tokens in tb1 and append them to new rows of the tab\n",
        "for token in tb1.tokens:\n",
        "    tab.add_row([index,token])\n",
        "    index += 1\n",
        "\n",
        "print(tab)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTawUcseRA7l"
      },
      "source": [
        "## Q.No: 2  POS Tagging\n",
        "\n",
        "Use NLTK and Textblob libraries to do POS tagging.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "text1 = \"\"\"\n",
        "It is also Apple’s answer to Wall Street’s questions about its AI strategy.\n",
        "Apple has taken a different path with its device-based AI than its megacap rivals,\n",
        "which are focused on cloud-based AI systems powered by billions of dollars of Nvidia chips.\n",
        "\"\"\"\n",
        "\n",
        "# Define a function that turns the text into a TextBlob, gets the tags from\n",
        "# the textblob and then returns the tags.\n",
        "\n",
        "\n",
        "# Get the POS tags using the created function.\n",
        "\n",
        "\n",
        "# Display POS tags\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jcF9zZYvTxJ5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPstY5OHRA7l",
        "outputId": "a6ea7bde-c412-4c92-cca5-507bf152a1bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Part-of-Speech Tags:\n",
            " - It: PRP\n",
            " - is: VBZ\n",
            " - also: RB\n",
            " - Apple: NNP\n",
            " - ’: NNP\n",
            " - s: VBD\n",
            " - answer: JJR\n",
            " - to: TO\n",
            " - Wall: NNP\n",
            " - Street: NNP\n",
            " - ’: NNP\n",
            " - s: JJ\n",
            " - questions: NNS\n",
            " - about: IN\n",
            " - its: PRP$\n",
            " - AI: NNP\n",
            " - strategy: NN\n",
            " - Apple: NNP\n",
            " - has: VBZ\n",
            " - taken: VBN\n",
            " - a: DT\n",
            " - different: JJ\n",
            " - path: NN\n",
            " - with: IN\n",
            " - its: PRP$\n",
            " - device-based: JJ\n",
            " - AI: NNP\n",
            " - than: IN\n",
            " - its: PRP$\n",
            " - megacap: NN\n",
            " - rivals: NNS\n",
            " - which: WDT\n",
            " - are: VBP\n",
            " - focused: VBN\n",
            " - on: IN\n",
            " - cloud-based: JJ\n",
            " - AI: NNP\n",
            " - systems: NNS\n",
            " - powered: VBN\n",
            " - by: IN\n",
            " - billions: NNS\n",
            " - of: IN\n",
            " - dollars: NNS\n",
            " - of: IN\n",
            " - Nvidia: NNP\n",
            " - chips: NNS\n"
          ]
        }
      ],
      "source": [
        "# SOLUTION\n",
        "\n",
        "text1 = \"\"\"\n",
        "It is also Apple’s answer to Wall Street’s questions about its AI strategy.\n",
        "Apple has taken a different path with its device-based AI than its megacap rivals,\n",
        "which are focused on cloud-based AI systems powered by billions of dollars of Nvidia chips.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def pos_tagging_with_textblob(text):\n",
        "    # Create a TextBlob object\n",
        "    blob = TextBlob(text)\n",
        "\n",
        "    # Perform POS tagging\n",
        "    pos_tags = blob.tags\n",
        "\n",
        "    return pos_tags\n",
        "\n",
        "\n",
        "# Get POS tags\n",
        "tags = pos_tagging_with_textblob(text1)\n",
        "\n",
        "# Display POS tags\n",
        "print(\"Part-of-Speech Tags:\")\n",
        "for word, tag in tags:\n",
        "    print(f\" - {word}: {tag}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eRiUh7tRA7m"
      },
      "source": [
        "## Q.No: 3 Stemming\n",
        "\n",
        "Use the nltk packages to stem the words from the following sentense.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hint: these should be used.\n",
        "\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize"
      ],
      "metadata": {
        "id": "Im2OpmN_U5MB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "textdoc = \"Mark Twain: Twenty years from now you will be more disappointed \"+ \\\n",
        "\"by the things that you didn’t do than by the ones you did do.\"\n",
        "\n",
        "\n",
        "# Instantiate the stemmer\n",
        "\n",
        "\n",
        "# Tokenize the text\n",
        "\n",
        "\n",
        "# Apply the stemmer on the words\n",
        "\n",
        "\n",
        "# Print out the stemmed sentence in readable form with the token and stemmed token.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UXWgHNesUznZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlZpjQ9lRA7m",
        "outputId": "44830362-d189-4d3b-f234-dd8ebf4d839c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using NLTK stemming  \n",
            "\n",
            "\n",
            "Stemmed sentence: \n",
            " mark twain : twenti year from now you will be more disappoint by the thing that you didn ’ t do than by the one you did do .\n",
            "Stemmed Tokens using NLTK: \n",
            "+--------------+---------------+\n",
            "|    Token     | Stemmed Token |\n",
            "+--------------+---------------+\n",
            "|     Mark     |      mark     |\n",
            "|    Twain     |     twain     |\n",
            "|      :       |       :       |\n",
            "|    Twenty    |     twenti    |\n",
            "|    years     |      year     |\n",
            "|     from     |      from     |\n",
            "|     now      |      now      |\n",
            "|     you      |      you      |\n",
            "|     will     |      will     |\n",
            "|      be      |       be      |\n",
            "|     more     |      more     |\n",
            "| disappointed |   disappoint  |\n",
            "|      by      |       by      |\n",
            "|     the      |      the      |\n",
            "|    things    |     thing     |\n",
            "|     that     |      that     |\n",
            "|     you      |      you      |\n",
            "|     didn     |      didn     |\n",
            "|      ’       |       ’       |\n",
            "|      t       |       t       |\n",
            "|      do      |       do      |\n",
            "|     than     |      than     |\n",
            "|      by      |       by      |\n",
            "|     the      |      the      |\n",
            "|     ones     |      one      |\n",
            "|     you      |      you      |\n",
            "|     did      |      did      |\n",
            "|      do      |       do      |\n",
            "|      .       |       .       |\n",
            "+--------------+---------------+\n"
          ]
        }
      ],
      "source": [
        "# SOLUTION\n",
        "\n",
        "textdoc = \"Mark Twain: Twenty years from now you will be more disappointed \"+ \\\n",
        "\"by the things that you didn’t do than by the ones you did do.\"\n",
        "\n",
        "# Stemmer\n",
        "st = PorterStemmer()\n",
        "\n",
        "# Tokenize the text\n",
        "words = word_tokenize(textdoc)\n",
        "\n",
        "# Apply the stemmer on the words\n",
        "stem_words = [st.stem(word) for word in words]\n",
        "\n",
        "# Print out the stemmed sentence in readable form with the token and stemmed token.\n",
        "print('Using NLTK stemming  \\n\\n')\n",
        "print('Stemmed sentence: \\n', ' '.join(stem_words))\n",
        "\n",
        "tab = PrettyTable(['Token', 'Stemmed Token'])\n",
        "\n",
        "for word in words:\n",
        "    tab.add_row([word, st.stem(word)])\n",
        "\n",
        "print('Stemmed Tokens using NLTK: ')\n",
        "print(tab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHgTk1g2RA7m"
      },
      "source": [
        "## Q.No: 4 Lemmatization\n",
        "\n",
        "Use the textblob or nltk packages to Lemmatize the words from the following sentenses and compare the results with stemming.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "textdoc = \"Mark Twain: Twenty years from now you will be more disappointed \"+ \\\n",
        "\"by the things that you didn’t do than by the ones you did do.\"\n",
        "\n",
        "# Instantiate the Lemmatizer\n",
        "\n",
        "\n",
        "# Lemmatize words from the quote using e.g. the nltk wordnet lemmatizer\n",
        "\n",
        "\n",
        "# Print out the lemmatized sentence in readable form showing the token and lemma.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CNx1FWDUYOk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPiwkm5BRA7n",
        "outputId": "ba907b35-3c7d-49b9-d481-c1c350a46d20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemmatization NLTK: \n",
            "Sentence: after lemmaitization using NLTK \n",
            " Mark Twain : Twenty year from now you will be more disappointed by the thing that you didn ’ t do than by the one you did do .\n",
            "+--------------+--------------+\n",
            "|    Token     |    Lemma     |\n",
            "+--------------+--------------+\n",
            "|     Mark     |     Mark     |\n",
            "|    Twain     |    Twain     |\n",
            "|      :       |      :       |\n",
            "|    Twenty    |    Twenty    |\n",
            "|    years     |     year     |\n",
            "|     from     |     from     |\n",
            "|     now      |     now      |\n",
            "|     you      |     you      |\n",
            "|     will     |     will     |\n",
            "|      be      |      be      |\n",
            "|     more     |     more     |\n",
            "| disappointed | disappointed |\n",
            "|      by      |      by      |\n",
            "|     the      |     the      |\n",
            "|    things    |    thing     |\n",
            "|     that     |     that     |\n",
            "|     you      |     you      |\n",
            "|     didn     |     didn     |\n",
            "|      ’       |      ’       |\n",
            "|      t       |      t       |\n",
            "|      do      |      do      |\n",
            "|     than     |     than     |\n",
            "|      by      |      by      |\n",
            "|     the      |     the      |\n",
            "|     ones     |     one      |\n",
            "|     you      |     you      |\n",
            "|     did      |     did      |\n",
            "|      do      |      do      |\n",
            "|      .       |      .       |\n",
            "+--------------+--------------+\n"
          ]
        }
      ],
      "source": [
        "# SOLUTION\n",
        "\n",
        "textdoc = \"Mark Twain: Twenty years from now you will be more disappointed \"+ \\\n",
        "\"by the things that you didn’t do than by the ones you did do.\"\n",
        "\n",
        "\n",
        "# Instantiate the lemmatizer\n",
        "wnl = nltk.WordNetLemmatizer()\n",
        "\n",
        "# Lemmatize words from the quote using nltk wordnet lemmatizer\n",
        "print('Lemmatization NLTK: ')\n",
        "lemma_words = [wnl.lemmatize(word) for word in words]\n",
        "\n",
        "\n",
        "# Print out the lemmatized sentence in readable form showing the token and lemma.\n",
        "print('Sentence: after lemmaitization using NLTK \\n', ' '.join(lemma_words))\n",
        "\n",
        "tab = PrettyTable(['Token', 'Lemma'])\n",
        "\n",
        "for word in words:\n",
        "    tab.add_row([word, wnl.lemmatize(word)])\n",
        "\n",
        "print(tab)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}